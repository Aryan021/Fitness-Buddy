{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Agents Lab Notebook v1.0.0\n",
    ">\n",
    "> This notebook contains steps and code to demonstrate the use of agents\n",
    "> configured in Agent Lab in watsonx.ai. It introduces Python API\n",
    "> commands for authentication using API key and invoking a LangGraph\n",
    "> agent with a watsonx chat model.\n",
    ">\n",
    "> Note: Notebook code generated using Agent Lab will execute\n",
    "> successfully. If code is modified or reordered, there is no guarantee\n",
    "> it will successfully execute. For details, see: Saving your work in\n",
    "> Agent Lab as a notebook.\n",
    ">\n",
    "> Some familiarity with Python is helpful. This notebook uses Python\n",
    "> 3.11. Notebook goals\n",
    ">\n",
    "> The learning goals of this notebook are:\n",
    ">\n",
    "> Defining a Python function for obtaining credentials from the IBM\n",
    "> Cloud personal API key  \n",
    "> Creating an agent with a set of tools using a specified model and\n",
    "> parameters Invoking the agent to generate a response\n",
    ">\n",
    "> Setup\n",
    ">\n",
    "> \\# import dependencies  \n",
    "> from langchain_ibm import ChatWatsonx  \n",
    "> from ibm_watsonx_ai import APIClient  \n",
    "> from langchain_core.messages import AIMessage, HumanMessage from\n",
    "> langgraph.checkpoint.memory import MemorySaver  \n",
    "> from langgraph.prebuilt import create_react_agent  \n",
    "> from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
    "> import json  \n",
    "> import requests\n",
    ">\n",
    "> watsonx API connection\n",
    ">\n",
    "> This cell defines the credentials required to work with watsonx API\n",
    "> for Foundation Model inferencing.\n",
    "\n",
    "Action: Provide the IBM Cloud personal API key. For details, see\n",
    "documentation.\n",
    "\n",
    "> import os  \n",
    "> import getpass\n",
    ">\n",
    "> def get_credentials():  \n",
    "> return {  \n",
    "> \"url\" : \"https://eu-gb.ml.cloud.ibm.com\",  \n",
    "> \"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n",
    ">\n",
    "> }  \n",
    "> def get_bearer_token():  \n",
    "> url = \"https://iam.cloud.ibm.com/identity/token\"  \n",
    "> headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}  \n",
    "> data = f\"grant_type=urn:ibm:params:oauth:grant-  \n",
    "> type:apikey&apikey={credentials\\['apikey'\\]}\"  \n",
    "> response = requests.post(url, headers=headers, data=data)  \n",
    "> return response.json().get(\"access_token\")  \n",
    "> credentials = get_credentials()  \n",
    "> Using the agent  \n",
    "> These cells demonstrate how to create and invoke the agent with the\n",
    "> selected models, tools, and parameters.\n",
    ">\n",
    "> Defining the model id  \n",
    "> We need to specify model id that will be used for inferencing:  \n",
    "> model_id = \"meta-llama/llama-3-3-70b-instruct\"  \n",
    "> Defining the model parameters  \n",
    "> We need to provide a set of model parameters that will influence the\n",
    "> result: parameters = {  \n",
    "> \"frequency_penalty\": 0,  \n",
    "> \"max_tokens\": 2000,  \n",
    "> \"presence_penalty\": 0,  \n",
    "> \"temperature\": 0,  \n",
    "> \"top_p\": 1  \n",
    "> }  \n",
    "> Defining the project id or space id  \n",
    "> The API requires project id or space id that provides the context for\n",
    "> the call. We will obtain the id from the project or space in which\n",
    "> this notebook runs:  \n",
    "> project_id = os.getenv(\"PROJECT_ID\")  \n",
    "> space_id = os.getenv(\"SPACE_ID\")\n",
    ">\n",
    "> Creating the agent  \n",
    "> We need to create the agent using the properties we defined so far:\n",
    ">\n",
    "> client = APIClient(credentials=credentials, project_id=project_id,\n",
    "> space_id=space_id)\n",
    ">\n",
    "> \\# Create the chat model  \n",
    "> def create_chat_model():  \n",
    "> chat_model = ChatWatsonx(  \n",
    "> model_id=model_id,  \n",
    "> url=credentials\\[\"url\"\\],  \n",
    "> space_id=space_id,  \n",
    "> project_id=project_id,  \n",
    "> params=parameters,  \n",
    "> watsonx_client=client,  \n",
    "> )  \n",
    "> return chat_model\n",
    ">\n",
    "> from ibm_watsonx_ai.deployments import RuntimeContext\n",
    ">\n",
    "> context = RuntimeContext(api_client=client)\n",
    ">\n",
    "> def create_utility_agent_tool(tool_name, params, api_client,\n",
    "> \\*\\*kwargs): from langchain_core.tools import StructuredTool  \n",
    "> utility_agent_tool = Toolkit(  \n",
    "> api_client=api_client  \n",
    "> ).get_tool(tool_name)\n",
    ">\n",
    "> tool_description = utility_agent_tool.get(\"description\")\n",
    ">\n",
    "> if (kwargs.get(\"tool_description\")):  \n",
    "> tool_description = kwargs.get(\"tool_description\")  \n",
    "> elif (utility_agent_tool.get(\"agent_description\")):  \n",
    "> tool_description = utility_agent_tool.get(\"agent_description\")\n",
    ">\n",
    "> tool_schema = utility_agent_tool.get(\"input_schema\")  \n",
    "> if (tool_schema == None):  \n",
    "> tool_schema = {  \n",
    "> \"type\": \"object\",  \n",
    "> \"additionalProperties\": False,  \n",
    "> \"\\$schema\": \"http://json-schema.org/draft-07/schema#\", \"properties\":\n",
    "> {  \n",
    "> \"input\": {  \n",
    "> \"description\": \"input for the tool\",  \n",
    "> \"type\": \"string\"\n",
    ">\n",
    "> }  \n",
    "> }  \n",
    "> }\n",
    ">\n",
    "> def run_tool(\\*\\*tool_input):  \n",
    "> query = tool_input  \n",
    "> if (utility_agent_tool.get(\"input_schema\") == None): query =\n",
    "> tool_input.get(\"input\")\n",
    ">\n",
    "> results = utility_agent_tool.run(  \n",
    "> input=query,  \n",
    "> config=params  \n",
    "> )\n",
    ">\n",
    "> return results.get(\"output\")\n",
    ">\n",
    "> return StructuredTool(  \n",
    "> name=tool_name,  \n",
    "> description = tool_description,  \n",
    "> func=run_tool,  \n",
    "> args_schema=tool_schema  \n",
    "> )\n",
    ">\n",
    "> def create_custom_tool(tool_name, tool_description, tool_code,\n",
    "> tool_schema, tool_params):  \n",
    "> from langchain_core.tools import StructuredTool  \n",
    "> import ast\n",
    ">\n",
    "> def call_tool(\\*\\*kwargs):  \n",
    "> tree = ast.parse(tool_code, mode=\"exec\")  \n",
    "> custom_tool_functions = \\[ x for x in tree.body if isinstance(x,\n",
    "> ast.FunctionDef) \\]  \n",
    "> function_name = custom_tool_functions\\[0\\].name  \n",
    "> compiled_code = compile(tree, 'custom_tool', 'exec')  \n",
    "> namespace = tool_params if tool_params else {}  \n",
    "> exec(compiled_code, namespace)  \n",
    "> return namespace\\[function_name\\](\\*\\*kwargs)\n",
    ">\n",
    "> tool = StructuredTool(  \n",
    "> name=tool_name,  \n",
    "> description = tool_description,  \n",
    "> func=call_tool,  \n",
    "> args_schema=tool_schema  \n",
    "> )  \n",
    "> return tool\n",
    ">\n",
    "> def create_custom_tools():  \n",
    "> custom_tools = \\[\\]\n",
    ">\n",
    "> def create_tools(context):  \n",
    "> tools = \\[\\]\n",
    ">\n",
    "> config = None  \n",
    "> tools.append(create_utility_agent_tool(\"GoogleSearch\", config,\n",
    "> client))\n",
    ">\n",
    "> return tools\n",
    ">\n",
    "> def create_agent(context):  \n",
    "> \\# Initialize the agent  \n",
    "> chat_model = create_chat_model()  \n",
    "> tools = create_tools(context)\n",
    ">\n",
    "> memory = MemorySaver()  \n",
    "> instructions = \"\"\"# Notes  \n",
    "> - Use markdown syntax for formatting code snippets, links, JSON,\n",
    "> tables, images, files.\n",
    ">\n",
    "> \\- Any HTML tags must be wrapped in block quotes, for example\n",
    "> \\`\\`\\`\\`\\`\\`.\n",
    ">\n",
    "> \\- When returning code blocks, specify language.\n",
    ">\n",
    "> \\- Sometimes, things don't go as planned. Tools may not provide useful\n",
    "> information on the first few tries. You should always try a few\n",
    "> different approaches before declaring the problem unsolvable.\n",
    ">\n",
    "> \\- When the tool doesn't give you what you were asking for, you must\n",
    "> either use another tool or a different tool input.\n",
    ">\n",
    "> \\- When using search engines, you try different formulations of the\n",
    "> query, possibly even in a different language.\n",
    ">\n",
    "> \\- You cannot do complex calculations, computations, or data\n",
    "> manipulations without using tools.\n",
    ">\n",
    "> \\- If you need to call a tool to compute something, always call it\n",
    "> instead of saying you will call it.\n",
    ">\n",
    "> If a tool returns an IMAGE in the result, you must include it in your\n",
    "> answer as Markdown.\n",
    ">\n",
    "> Example:\n",
    ">\n",
    "> Tool result:\n",
    "> IMAGE({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/\n",
    "> images/plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)  \n",
    "> Markdown to return to user: !\\[Generated\n",
    "> image\\]({commonApiUrl}/wx/v1-beta/ utility_agent_tools/cache/images/  \n",
    "> plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)\n",
    ">\n",
    "> You are a helpful assistant that uses tools to answer questions in\n",
    "> detail. When greeted, say \\\\\"Hi, I am watsonx.ai agent. How can I help\n",
    "> you?\\\\\"\"\"\"\n",
    ">\n",
    "> agent = create_react_agent(chat_model, tools=tools,\n",
    "> checkpointer=memory, state_modifier=instructions)\n",
    ">\n",
    "> return agent\n",
    ">\n",
    "> \\# Visualize the graph  \n",
    "> from IPython.display import Image, display  \n",
    "> from langchain_core.runnables.graph import CurveStyle,\n",
    "> MermaidDrawMethod, NodeStyles\n",
    ">\n",
    "> Image(  \n",
    "> create_agent(context).get_graph().draw_mermaid_png(\n",
    "> draw_method=MermaidDrawMethod.API,  \n",
    "> )  \n",
    "> )\n",
    ">\n",
    "> Invoking the agent\n",
    ">\n",
    "> Let us now use the created agent, pair it with the input, and generate\n",
    "> the response to your question:\n",
    ">\n",
    "> agent = create_agent(context)\n",
    ">\n",
    "> def convert_messages(messages):  \n",
    "> converted_messages = \\[\\]  \n",
    "> for message in messages:  \n",
    "> if (message\\[\"role\"\\] == \"user\"):\n",
    ">\n",
    "> converted_messages.append(HumanMessage(content=message\\[\"content\"\\]))\n",
    "> elif (message\\[\"role\"\\] == \"assistant\"):\n",
    ">\n",
    "> converted_messages.append(AIMessage(content=message\\[\"content\"\\]))\n",
    "> return converted_messages\n",
    ">\n",
    "> question = input(\"Question: \")\n",
    ">\n",
    "> messages = \\[{  \n",
    "> \"role\": \"user\",  \n",
    "> \"content\": question  \n",
    "> }\\]\n",
    ">\n",
    "> generated_response = agent.invoke(  \n",
    "> { \"messages\": convert_messages(messages) }, { \"configurable\": {\n",
    "> \"thread_id\": \"42\" } }  \n",
    "> )\n",
    ">\n",
    "> print_full_response = False\n",
    ">\n",
    "> if (print_full_response):  \n",
    "> print(generated_response)  \n",
    "> else:  \n",
    "> result = generated_response\\[\"messages\"\\]\\[-1\\].content print(f\"Agent:\n",
    "> {result}\")\n",
    ">\n",
    "> Next steps\n",
    ">\n",
    "> You successfully completed this notebook! You learned how to use\n",
    "> watsonx.ai inferencing SDK to generate response from the foundation\n",
    "> model based on the provided input, model id and model parameters.\n",
    "> Check out the official  \n",
    "> watsonx.ai site for more samples, tutorials, documentation, how-tos,\n",
    "> and blog posts.\n",
    ">\n",
    "> Copyrights\n",
    ">\n",
    "> Licensed Materials - Copyright Â© 2024 IBM. This notebook and its\n",
    "> source code are released under the terms of the ILAN License. Use,\n",
    "> duplication disclosure restricted by GSA ADP Schedule Contract with\n",
    "> IBM Corp.\n",
    ">\n",
    "> Note: The auto-generated notebooks are subject to the International\n",
    "> License Agreement for Non-Warranted Programs (or equivalent) and\n",
    "> License  \n",
    "> Information document for watsonx.ai Auto-generated Notebook (License\n",
    "> Terms), such agreements located in the link below. Specifically, the\n",
    "> Source Components and Sample Materials clause included in the License\n",
    "> Information document for watsonx.ai Studio Auto-generated Notebook\n",
    "> applies to the auto-generated notebooks.\n",
    ">\n",
    "> By downloading, copying, accessing, or otherwise using the materials,\n",
    "> you agree to the License Terms"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
